@inproceedings{alistarh2017qsgd,
  title={{QSGD}: Communication-efficient {SGD} via gradient quantization and encoding},
  author={Alistarh, Dan and Grubic, Demjan and Li, Jerry and Tomioka, Ryota and Vojnovic, Milan},
  booktitle={Advances in Neural Information Processing Systems (NIPS)},
  year={2017}
}


@article{bonawitz2017practical,
	title={Practical Secure Aggregation for Privacy Preserving Machine Learning},
	author={Bonawitz, Keith and Ivanov, Vladimir and Kreuter, Ben and Marcedone, Antonio and McMahan, H Brendan and Patel, Sarvar and Ramage, Daniel and Segal, Aaron and Seth, Karn},
	journal={IACR Cryptology ePrint Archive},
	volume={2017},
	pages={281},
	year={2017}
}

@article{jeong2018communication,
  title={Communication-efficient on-device machine learning: Federated distillation and augmentation under non-iid private data},
  author={Jeong, Eunjeong and Oh, Seungeun and Kim, Hyesung and Park, Jihong and Bennis, Mehdi and Kim, Seong-Lyun},
  journal={arXiv preprint arXiv:1811.11479},
  year={2018}
}

@inproceedings{zinkevich2010parallelized,
  title={Parallelized stochastic gradient descent},
  author={Zinkevich, Martin and Weimer, Markus and Li, Lihong and Smola, Alex J},
  booktitle={Advances in neural information processing systems},
  pages={2595--2603},
  year={2010}
}

@inproceedings{you2018imagenet,
  title={Imagenet training in minutes},
  author={You, Yang and Zhang, Zhao and Hsieh, Cho-Jui and Demmel, James and Keutzer, Kurt},
  booktitle={Proceedings of the 47th International Conference on Parallel Processing},
  pages={1},
  year={2018},
  organization={ACM}
}

@article{chen2018differentially,
  title={Differentially Private Data Generative Models},
  author={Chen, Qingrong and Xiang, Chong and Xue, Minhui and Li, Bo and Borisov, Nikita and Kaarfar, Dali and Zhu, Haojin},
  journal={arXiv preprint arXiv:1812.02274},
  year={2018}
}

@article{dwork2010difficulties,
  title={On the difficulties of disclosure prevention in statistical databases or the case for differential privacy},
  author={Dwork, Cynthia and Naor, Moni},
  journal={Journal of Privacy and Confidentiality},
  volume={2},
  number={1},
  year={2010}
}

@article{dwork2011differential,
  title={Differential privacy},
  author={Dwork, Cynthia},
  journal={Encyclopedia of Cryptography and Security},
  pages={338--340},
  year={2011},
  publisher={Springer}
}



@InProceedings{haddadpour19a,
	title = 	 {Trading Redundancy for Communication: Speeding up Distributed {SGD} for Non-convex Optimization},
	author = 	 {Haddadpour, Farzin and Kamani, Mohammad Mahdi and Mahdavi, Mehrdad and Cadambe, Viveck},
	booktitle = 	 {International Conference on Machine Learning (ICML)},
	year = 	 {2019}
}

@inproceedings{hitaj2017deep,
  title={Deep models under the {GAN}: information leakage from collaborative deep learning},
  author={Hitaj, Briland and Ateniese, Giuseppe and Perez-Cruz, Fernando},
  booktitle={Proceedings of the 2017 ACM SIGSAC Conference on Computer and Communications Security},
  year={2017}
}


@inproceedings{hong2018gradient,
  title={Gradient Primal-Dual Algorithm Converges to Second-Order Stationary Solution for Nonconvex Distributed Optimization Over Networks},
  author={Hong, Mingyi and Razaviyayn, Meisam and Lee, Jason},
  booktitle={International Conference on Machine Learning (ICML)},
  year={2018}
}



@article{konevcny2016federated,
	title={Federated optimization: distributed machine learning for on-device intelligence},
	author={Kone{{c}}n{\`y}, Jakub and McMahan, H Brendan and Ramage, Daniel and Richt{\'a}rik, Peter},
	journal={arXiv preprint arXiv:1610.02527},
	year={2016}
}

@article{konevcny2017federated,
	title={Federated learning: strategies for improving communication efficiency},
	author={Jakub Kone{{c}}n{\`y} and H. Brendan McMahan and Felix X. Yu and Ananda Theertha Suresh and Dave Bacon and Peter Richt{\'a}rik},
	journal={arXiv preprint arXiv:1610.05492},
	year={2017}
}


@article{lee2017communication,
  title={Communication-efficient sparse regression},
  author={Lee, Jason D and Liu, Qiang and Sun, Yuekai and Taylor, Jonathan E},
  journal={The Journal of Machine Learning Research},
  volume={18},
  number={1},
  pages={115--144},
  year={2017}
}


@article{li2019convergence,
    author  = {Xiang Li and Kaixuan Huang and Wenhao Yang and Shusen Wang and Zhihua Zhang},
    title   = {On the Convergence of {FedAvg} on {Non-IID} Data},
    year    = {2019},
    journal = {arXiv:1907.02189}
}


@article{lin2017distributed,
  title={Distributed learning with regularized least squares},
  author={Lin, Shao-Bo and Guo, Xin and Zhou, Ding-Xuan},
  journal={Journal of Machine Learning Research},
  volume={18},
  number={1},
  pages={3202--3232},
  year={2017}
}

@article{lin2018don,
	title={Don't Use Large Mini-Batches, Use Local SGD},
	author={Lin, Tao and Stich, Sebastian U and Jaggi, Martin},
	journal={arXiv preprint arXiv:1808.07217},
	year={2018}
}

@article{liu2019lifelong,
  title={Lifelong Federated Reinforcement Learning: A Learning Architecture for Navigation in Cloud Robotic Systems},
  author={Liu, Boyi and Wang, Lujia and Liu, Ming and Xu, Chengzhong},
  journal={arXiv preprint arXiv:1901.06455},
  year={2019}
}




@article{mahajan2018efficient,
  title={An efficient distributed learning algorithm based on effective local functional approximations},
  author={Mahajan, Dhruv and Agrawal, Nikunj and Keerthi, S Sathiya and Sellamanickam, Sundararajan and Bottou, L{\'e}on},
  journal={Journal of Machine Learning Research},
  volume={19},
  number={1},
  pages={2942--2978},
  year={2018}
}



@inproceedings{melis2019exploiting,
  title={Exploiting unintended feature leakage in collaborative learning},
  author={Melis, Luca and Song, Congzheng and De Cristofaro, Emiliano and Shmatikov, Vitaly},
  year={2019},
  organization={IEEE}
}

@inproceedings{mcmahan2017communication,
  title={Communication-Efficient Learning of Deep Networks from Decentralized Data},
  author={McMahan, Brendan and Moore, Eider and Ramage, Daniel and Hampson, Seth and y Arcas, Blaise Aguera},
  booktitle={Artificial Intelligence and Statistics (AISTATS)},
  year={2017}
}

@inproceedings{recht2011hogwild,
  title={Hogwild: A lock-free approach to parallelizing stochastic gradient descent},
  author={Recht, Benjamin and Re, Christopher and Wright, Stephen and Niu, Feng},
  booktitle={Advances in Neural Information Processing Systems (NIPS)},
  year={2011}
}

@article{reddi2016aide,
	title={{AIDE}: {f}ast and communication efficient distributed optimization},
	author={Reddi, Sashank J and Kone{{c}}n{\`y}, Jakub and Richt{\'a}rik, Peter and P{\'o}cz{\'o}s, Barnab{\'a}s and Smola, Alex},
	journal={arXiv preprint arXiv:1608.06879},
	year={2016}
}

@article{sahu2019federated,
	title={Federated Optimization for Heterogeneous Networks},
	author={Anit Kumar Sahu and Tian Li and Maziar Sanjabi and Manzil Zaheer and Ameet Talwalkar and Virginia Smith},
	journal={arXiv preprint arXiv:1812.06127},
	year={2019}
}

@inproceedings{seide2014bit,
  title={1-bit stochastic gradient descent and its application to data-parallel distributed training of speech {DNNs}},
  author={Seide, Frank and Fu, Hao and Droppo, Jasha and Li, Gang and Yu, Dong},
  booktitle={Fifteenth Annual Conference of the International Speech Communication Association},
  year={2014}
}


@inproceedings{shamir2014communication,
	title={Communication-efficient distributed optimization using an approximate {N}ewton-type method},
	author={Shamir, Ohad and Srebro, Nati and Zhang, Tong},
	booktitle={International conference on machine learning (ICML)},
	year={2014}
}



@inproceedings{shokri2015privacy,
  title={Privacy-preserving deep learning},
  author={Shokri, Reza and Shmatikov, Vitaly},
  booktitle={Proceedings of the 22nd ACM SIGSAC conference on computer and communications security},
  pages={1310--1321},
  year={2015},
  organization={ACM}
}


@article{sattler2019robust,
  title={Robust and Communication-Efficient Federated Learning from Non-IID Data},
  author={Sattler, Felix and Wiedemann, Simon and M{\"u}ller, Klaus-Robert and Samek, Wojciech},
  journal={arXiv preprint arXiv:1903.02891},
  year={2019}
}

@article{smith2016cocoa,
	title={{CoCoA}: A General Framework for Communication-Efficient Distributed Optimization},
	author={Smith, Virginia and Forte, Simone and Ma, Chenxin and Takac, Martin and Jordan, Michael I and Jaggi, Martin},
	journal={arXiv preprint arXiv:1611.02189},
	year={2016}
}


@inproceedings{smith2017federated,
  title={Federated multi-task learning},
  author={Smith, Virginia and Chiang, Chao-Kai and Sanjabi, Maziar and Talwalkar, Ameet S},
  booktitle={Advances in Neural Information Processing Systems (NIPS)},  
  year={2017}
}


@article{stich2018local,
	title={Local {SGD} converges fast and communicates little},
	author={Stich, Sebastian U},
	journal={arXiv preprint arXiv:1805.09767},
	year={2018}
}

@inproceedings{stich2018sparsified,
	title={Sparsified {SGD} with memory},
	author={Stich, Sebastian U and Cordonnier, Jean-Baptiste and Jaggi, Martin},
	booktitle={Advances in Neural Information Processing Systems (NIPS)},
	pages={4447--4458},
	year={2018}
}


@article{triastcyn2019federated,
  title={Federated Generative Privacy},
  author={Aleksei Triastcyn and Boi Faltings},
  journal={EPFL Tech. Report},
  year={2019}
}



@article{wang2018cooperative,
  title={Cooperative {SGD}: A unified framework for the design and analysis of communication-efficient {SGD} algorithms},
  author={Wang, Jianyu and Joshi, Gauri},
  journal={arXiv preprint arXiv:1808.07576},
  year={2018}
}



@inproceedings{wang2018giant,
	title={{GIANT}: Globally Improved Approximate Newton Method for Distributed Optimization},
	author={{S}husen {W}ang and {F}arbod {R}oosta-{K}horasani and {P}eng {X}u and {M}ichael {W}. {M}ahoney},
	booktitle = {{C}onference on {N}eural {I}nformation {P}rocessing {S}ystems ({{NeurIPS}})},
	year={2018}
}


@article{wang2019adaptive,
  title={Adaptive federated learning in resource constrained edge computing systems},
  author={Wang, Shiqiang and Tuor, Tiffany and Salonidis, Theodoros and Leung, Kin K and Makaya, Christian and He, Ting and Chan, Kevin},
  journal={IEEE Journal on Selected Areas in Communications},
  year={2019},
  publisher={IEEE}
}


@inproceedings{wang2019sharper,
  title={A Sharper Generalization Bound for Divide-and-Conquer Ridge Regression},
  author={Shusen Wang},
  booktitle={The Thirty-Third AAAI Conference on Artificial Intelligence (AAAI)},
  year={2019}
}

@inproceedings{wangni2018gradient,
  title={Gradient sparsification for communication-efficient distributed optimization},
  author={Wangni, Jianqiao and Wang, Jialei and Liu, Ji and Zhang, Tong},
  booktitle={Advances in Neural Information Processing Systems (NeurIPS)},
  year={2018}
}

@inproceedings{wen2017terngrad,
  title={Terngrad: Ternary gradients to reduce communication in distributed deep learning},
  author={Wen, Wei and Xu, Cong and Yan, Feng and Wu, Chunpeng and Wang, Yandan and Chen, Yiran and Li, Hai},
  booktitle={Advances in Neural Information Processing Systems (NIPS)},
  year={2017}
}


@inproceedings{woodworth2018graph,
  title={Graph oracle models, lower bounds, and gaps for parallel stochastic optimization},
  author={Woodworth, Blake E and Wang, Jialei and Smith, Adam and McMahan, Brendan and Srebro, Nati},
  booktitle={Advances in Neural Information Processing Systems (NeurIPS)},
  year={2018}
}



@article{xie2019asynchronous,
	title={Asynchronous Federated Optimization},
	author={Cong Xie and Sanmi Koyejo and Indranil Gupta},
	journal={arXiv preprint arXiv:1903.03934},
	year={2019}
}


@article{yang2019federated,
  title={Federated machine learning: Concept and applications},
  author={Yang, Qiang and Liu, Yang and Chen, Tianjian and Tong, Yongxin},
  journal={ACM Transactions on Intelligent Systems and Technology (TIST)},
  volume={10},
  number={2},
  pages={12},
  year={2019},
  publisher={ACM}
}

@inproceedings{yu2019parallel,
	title={Parallel restarted SGD with faster convergence and less communication: Demystifying why model averaging works for deep learning},
	author={Yu, Hao and Yang, Sen and Zhu, Shenghuo},
	booktitle={AAAI Conference on Artificial Intelligence},
	year={2019}
}


@InProceedings{yu2019linear,
	title = 	 {On the Linear Speedup Analysis of Communication Efficient Momentum {SGD} for Distributed Non-Convex Optimization},
	author = 	 {Yu, Hao and Jin, Rong and Yang, Sen},
	booktitle = 	 {International Conference on Machine Learning (ICML)},
	year = 	 {2019}
}




@article{zhang2013communication,
	title = {Communication-Efficient Algorithms for Statistical Optimization},
	author = {Yuchen Zhang and John C. Duchi and Martin J. Wainwright},
	journal = {Journal of Machine Learning Research},
	volume = {14},
	pages = {3321--3363},
	year = {2013}
}


@article{zhang2015divide,
	title={Divide and conquer kernel ridge regression: a distributed algorithm with minimax optimal rates},
	author={Zhang, Yuchen and Duchi, John and Wainwright, Martin},
	journal={Journal of Machine Learning Research},
	volume={16},
	pages={3299--3340},
	year={2015}
}

@article{zhuo2019federated,
    title={Federated Reinforcement Learning},
    author={Hankz Hankui Zhuo and Wenfeng Feng and Qian Xu and Qiang Yang and Yufeng Lin},
    year={2019},
    journal={arXiv preprint arXiv:1901.08277}
}


@article{konevcny2017stochastic,
  title={Stochastic, distributed and federated optimization for machine learning},
  author={Kone{\v{c}}n{\`y}, Jakub},
  journal={arXiv preprint arXiv:1707.01155},
  year={2017}
}

@article{konevcny2015federated,
	title={Federated optimization: distributed optimization beyond the datacenter},
	author={Kone{\v{c}}n{\`y}, Jakub and McMahan, Brendan and Ramage, Daniel},
	journal={arXiv preprint arXiv:1511.03575},
	year={2015}
}

@inproceedings{zhang2015disco,
	title={{DiSCO}: distributed optimization for Self-Concordant Empirical Loss},
	author={Zhang, Yuchen and Lin, Xiao},
	booktitle={International Conference on Machine Learning (ICML)},
	year={2015}
}


@article{zhao2018federated,
	title={Federated learning with non-iid data},
	author={Zhao, Yue and Li, Meng and Lai, Liangzhen and Suda, Naveen and Civin, Damon and Chandra, Vikas},
	journal={arXiv preprint arXiv:1806.00582},
	year={2018}
}

@article{zhou2017convergence,
  title={On the convergence properties of a K-step averaging stochastic gradient descent algorithm for nonconvex optimization},
  author={Zhou, Fan and Cong, Guojing},
  journal={arXiv preprint arXiv:1708.01012},
  year={2017}
}


@article{li2019federated,
  title={Federated Learning: Challenges, Methods, and Future Directions},
  author={Li, Tian and Sahu, Anit Kumar and Talwalkar, Ameet and Smith, Virginia},
  journal={arXiv preprint arXiv:1908.07873},
  year={2019}
}